# -*- coding: utf-8 -*-
"""
Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨
æ”¯æ´æ‰€æœ‰ç¾è²¨å’Œæ°¸çºŒåˆç´„äº¤æ˜“å°çš„åˆ†æ
"""

import math
import warnings
import os
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd

from binance_analyzer_config import BinanceAnalyzerConfig
from binance_api_utils import BinanceAPI

warnings.filterwarnings("ignore")


class BinanceTimeframeAnalyzer:
    """Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨"""
    
    def __init__(self, config: BinanceAnalyzerConfig):
        self.config = config
        self.df_1m = None
    
    def load_or_fetch_data(self) -> pd.DataFrame:
        """è¼‰å…¥æˆ–æŠ“å–è³‡æ–™"""
        if self.config.auto_fetch:
            print("=== è‡ªå‹•æŠ“å–æ¨¡å¼ ===")
            try:
                # é©—è­‰äº¤æ˜“å°
                if not BinanceAPI.validate_symbol(self.config.symbol, self.config.market_type):
                    raise ValueError(f"äº¤æ˜“å° {self.config.symbol} åœ¨ {self.config.market_type} å¸‚å ´ä¸å­˜åœ¨æˆ–ä¸å¯äº¤æ˜“")
                
                self.df_1m = BinanceAPI.fetch_historical_data(
                    self.config.symbol, 
                    self.config.market_type, 
                    self.config.data_days
                )
                
                if self.config.save_csv:
                    self.save_data_to_csv()
                
                return self.df_1m
                
            except Exception as e:
                print(f"è‡ªå‹•æŠ“å–å¤±æ•—: {e}")
                print("å˜—è©¦ä½¿ç”¨æœ¬åœ°CSVæª”æ¡ˆ...")
                return self.load_1m_csv()
        else:
            print("=== æœ¬åœ°CSVæ¨¡å¼ ===")
            return self.load_1m_csv()
    
    def save_data_to_csv(self) -> None:
        """å°‡è³‡æ–™å„²å­˜ç‚º CSV æª”æ¡ˆ"""
        try:
            os.makedirs(os.path.dirname(self.config.csv_path), exist_ok=True)
            self.df_1m.to_csv(self.config.csv_path, encoding='utf-8-sig')
            print(f"è³‡æ–™å·²å„²å­˜è‡³: {self.config.csv_path}")
        except Exception as e:
            print(f"å„²å­˜CSVæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def load_1m_csv(self) -> pd.DataFrame:
        """è®€å– 1m CSV æª”æ¡ˆ"""
        try:
            df = pd.read_csv(self.config.csv_path)
            
            # è½‰æ›æ™‚é–“æˆ³è¨˜
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')
            if df['timestamp'].isna().mean() > 0.5:
                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
            
            # è¨­å®šæ™‚å€
            if df['timestamp'].dt.tz is None:
                df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')
            
            # è½‰æ›è³‡æ–™é¡å‹
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = df[col].astype(float)
            
            df = df.set_index('timestamp').sort_index()
            return df
            
        except Exception as e:
            raise ValueError(f"è®€å–CSVæª”æ¡ˆå¤±æ•—: {e}")
    
    def resample_ohlcv(self, df_1m: pd.DataFrame, rule: str) -> pd.DataFrame:
        """ä»¥ OHLCV è¦å‰‡é‡æ¡æ¨£"""
        agg = {
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum'
        }
        return df_1m.resample(rule, label='right', closed='right').agg(agg).dropna(subset=['open', 'high', 'low', 'close'])
    
    def compute_atr(self, df: pd.DataFrame, period: int) -> pd.Series:
        """è¨ˆç®— ATR"""
        high = df['high']
        low = df['low']
        close = df['close']
        prev_close = close.shift(1)
        
        tr = pd.concat([
            (high - low),
            (high - prev_close).abs(),
            (low - prev_close).abs()
        ], axis=1).max(axis=1)
        
        atr = tr.rolling(period).mean()
        return atr
    
    def variance_ratio(self, returns: pd.Series, q: int) -> float:
        """è¨ˆç®— Variance Ratio"""
        r = returns.dropna()
        if len(r) < q + 2:
            return np.nan
        var_1 = np.var(r, ddof=1)
        r_q = r.rolling(q).sum()
        var_q = np.var(r_q.dropna(), ddof=1)
        if var_1 == 0:
            return np.nan
        return float(var_q / (q * var_1))
    
    def estimate_half_life_by_autocorr(self, returns: pd.Series, max_lag: int) -> Optional[float]:
        """ä¼°ç®—è¨Šè™ŸåŠè¡°æœŸ"""
        r = returns.dropna()
        if len(r) < max_lag + 5:
            return None
        
        r = r - r.mean()
        var = (r ** 2).sum()
        if var == 0:
            return None
        
        def autocorr(lag: int) -> float:
            return float((r[lag:] * r.shift(lag)[lag:]).sum() / var)
        
        rho1 = autocorr(1)
        if np.isnan(rho1) or abs(rho1) < 1e-6:
            return None
        
        target = 0.5 * abs(rho1)
        for k in range(2, max_lag + 1):
            rhok = autocorr(k)
            if np.isnan(rhok):
                continue
            if abs(rhok) <= target:
                return float(k)
        return None
    
    def bar_minutes(self, label: str) -> float:
        """å°‡æ™‚é–“æ¡†æ¶æ¨™ç±¤è½‰æ›ç‚ºåˆ†é˜æ•¸"""
        mapping = {
            "1m": 1, "5m": 5, "15m": 15,
            "1h": 60, "4h": 240,
            "1d": 1440, "1w": 10080
        }
        return float(mapping.get(label, 1.0))
    
    def get_min_bars_for_timeframe(self, tf_label: str) -> int:
        """æ ¹æ“šæ™‚é–“æ¡†æ¶å‹•æ…‹è¨ˆç®—æœ€å°è³‡æ–™é‡è¦æ±‚"""
        if not self.config.use_dynamic_min_bars:
            return self.config.n_min_bars_for_backtest
        
        min_days = self.config.min_days_per_timeframe.get(tf_label, 365)
        minutes_per_bar = self.bar_minutes(tf_label)
        min_bars = int((min_days * 24 * 60) / minutes_per_bar)
        min_bars = max(min_bars, 100)
        
        return min_bars
    
    def annualization_factor(self, tf_label: str) -> float:
        """è¨ˆç®—å¹´åŒ–å€æ•¸"""
        bars_per_year = (365.0 * 24.0 * 60.0) / self.bar_minutes(tf_label)
        return bars_per_year
    
    def apply_costs(self, returns: pd.Series, position: pd.Series, cost_one_way: float) -> pd.Series:
        """æ ¹æ“šéƒ¨ä½è®ŠåŒ–è¨ˆç®—äº¤æ˜“æˆæœ¬"""
        pos = position.fillna(0.0)
        pos_prev = pos.shift(1).fillna(0.0)
        turnover = (pos - pos_prev).abs()
        
        cost = turnover * cost_one_way
        net_ret = pos_prev * returns - cost
        return net_ret
    
    def sharpe_ratio(self, returns: pd.Series, ann_factor: float) -> float:
        """è¨ˆç®—å¤æ™®æ¯”ç‡"""
        r = returns.dropna()
        if len(r) < 2:
            return np.nan
        mean = r.mean() * ann_factor
        std = r.std(ddof=1) * math.sqrt(ann_factor)
        return float(mean / std) if std > 0 else np.nan
    
    def max_drawdown(self, equity_curve: pd.Series) -> float:
        """è¨ˆç®—æœ€å¤§å›æ’¤"""
        peak = equity_curve.cummax()
        dd = equity_curve / peak - 1.0
        return float(dd.min()) if len(dd) else np.nan
    
    def profit_factor(self, returns: pd.Series) -> float:
        """è¨ˆç®—ç²åˆ©å› å­"""
        gains = returns[returns > 0].sum()
        losses = -returns[returns < 0].sum()
        if losses == 0:
            return np.inf if gains > 0 else np.nan
        return float(gains / losses)
    
    def hit_rate(self, returns: pd.Series) -> float:
        """è¨ˆç®—å‹ç‡"""
        r = returns.dropna()
        if len(r) == 0:
            return np.nan
        return float((r > 0).mean())
    
    def ma_trend_positions(self, close: pd.Series, fast: int, slow: int) -> pd.Series:
        """MA è¶¨å‹¢ç­–ç•¥"""
        if slow <= fast:
            return pd.Series(index=close.index, dtype=float)
        f = close.rolling(fast).mean()
        s = close.rolling(slow).mean()
        pos = np.where(f > s, 1.0, np.where(f < s, -1.0, 0.0))
        return pd.Series(pos, index=close.index, dtype=float)
    
    def rsi(self, series: pd.Series, window: int = 14) -> pd.Series:
        """è¨ˆç®— RSI æŒ‡æ¨™"""
        delta = series.diff()
        up = delta.clip(lower=0.0)
        down = -delta.clip(upper=0.0)
        roll_up = up.rolling(window).mean()
        roll_down = down.rolling(window).mean()
        rs = roll_up / (roll_down + 1e-12)
        return 100.0 - (100.0 / (1.0 + rs))
    
    def rsi_mr_positions(self, close: pd.Series, window: int, lower: int, upper: int) -> pd.Series:
        """RSI å‡å€¼å›æ­¸ç­–ç•¥"""
        r = self.rsi(close, window)
        pos = np.where(r < lower, 1.0, np.where(r > upper, -1.0, 0.0))
        return pd.Series(pos, index=close.index, dtype=float)
    
    def backtest_positions(self, ohlc: pd.DataFrame, position: pd.Series, cost_one_way: float, ann_factor: float) -> Dict[str, float]:
        """å›æ¸¬ç­–ç•¥è¡¨ç¾"""
        px = ohlc['close']
        ret = px.pct_change().fillna(0.0)
        net = self.apply_costs(ret, position, cost_one_way)
        eq = (1.0 + net).cumprod()
        
        metrics = {
            "AnnRet": float((eq.iloc[-1] ** (ann_factor / max(len(eq), 1)) - 1.0)) if len(eq) > 0 else np.nan,
            "Sharpe": self.sharpe_ratio(net, ann_factor),
            "MDD": self.max_drawdown(eq),
            "PF": self.profit_factor(net),
            "HitRate": self.hit_rate(net),
            "TradesPerYear": float((position.diff().abs().fillna(0.0).sum() / 2.0) * (ann_factor / max(len(position), 1))),
            "AvgTurnover": float(position.diff().abs().fillna(0.0).mean())
        }
        return metrics
    
    def param_search_ma(self, ohlc: pd.DataFrame, cost_one_way: float, ann_factor: float) -> Tuple[Tuple[int, int], Dict[str, float]]:
        """MA ç­–ç•¥åƒæ•¸æœå°‹"""
        best_param = None
        best_metric = -np.inf
        best_stats = {}
        close = ohlc['close']
        
        for f in self.config.ma_fast_grid:
            for s in self.config.ma_slow_grid:
                if s <= f:
                    continue
                pos = self.ma_trend_positions(close, f, s)
                stats = self.backtest_positions(ohlc, pos, cost_one_way, ann_factor)
                score = stats["Sharpe"]
                if not np.isnan(score) and score > best_metric:
                    best_metric = score
                    best_param = (f, s)
                    best_stats = stats
        return best_param, best_stats
    
    def param_search_rsi(self, ohlc: pd.DataFrame, cost_one_way: float, ann_factor: float) -> Tuple[Tuple[int, int, int], Dict[str, float]]:
        """RSI ç­–ç•¥åƒæ•¸æœå°‹"""
        best_param = None
        best_metric = -np.inf
        best_stats = {}
        close = ohlc['close']
        
        for w in self.config.rsi_window_grid:
            for (lo, up) in self.config.rsi_band_grid:
                pos = self.rsi_mr_positions(close, w, lo, up)
                stats = self.backtest_positions(ohlc, pos, cost_one_way, ann_factor)
                score = stats["Sharpe"]
                if not np.isnan(score) and score > best_metric:
                    best_metric = score
                    best_param = (w, lo, up)
                    best_stats = stats
        return best_param, best_stats
    
    def walk_forward_oos(self, ohlc: pd.DataFrame, strategy: str, cost_one_way: float, ann_factor: float) -> Tuple[Dict[str, float], Dict[str, float]]:
        """Walk-forward æ¨£æœ¬å¤–è©•ä¼°"""
        n = len(ohlc)
        train_len = int(n * self.config.wf_train_ratio)
        test_len = int(n * self.config.wf_test_ratio)
        if train_len < 200 or test_len < 100:
            return {}, {}
        
        oos_metrics = []
        chosen_params = []
        
        start = 0
        while start + train_len + test_len <= n:
            train = ohlc.iloc[start:start + train_len]
            test = ohlc.iloc[start + train_len:start + train_len + test_len]
            
            if strategy == "MA":
                param, _ = self.param_search_ma(train, cost_one_way, ann_factor)
                if param is None:
                    start += test_len
                    continue
                f, s = param
                pos = self.ma_trend_positions(test['close'], f, s)
            elif strategy == "RSI":
                param, _ = self.param_search_rsi(train, cost_one_way, ann_factor)
                if param is None:
                    start += test_len
                    continue
                w, lo, up = param
                pos = self.rsi_mr_positions(test['close'], w, lo, up)
            else:
                raise ValueError("æœªçŸ¥ç­–ç•¥")
            
            stats = self.backtest_positions(test, pos, cost_one_way, ann_factor)
            oos_metrics.append(stats)
            chosen_params.append(param)
            start += test_len
        
        if not oos_metrics:
            return {}, {}
        
        # èšåˆ OOS æŒ‡æ¨™
        oos_df = pd.DataFrame(oos_metrics)
        oos_summary = {
            "OOS_AnnRet": float(oos_df["AnnRet"].mean()),
            "OOS_Sharpe": float(oos_df["Sharpe"].mean()),
            "OOS_MDD": float(oos_df["MDD"].mean()),
            "OOS_PF": float(oos_df["PF"].mean()),
            "OOS_HitRate": float(oos_df["HitRate"].mean()),
            "OOS_TradesPerYear": float(oos_df["TradesPerYear"].mean())
        }
        
        last_param = chosen_params[-1] if chosen_params else None
        chosen_param_dict = {"BestTrainParam_LastFold": str(last_param)}
        return oos_summary, chosen_param_dict
    
    def analyze_timeframes(self) -> pd.DataFrame:
        """åˆ†ææ‰€æœ‰æ™‚é–“æ¡†æ¶"""
        print("=== é–‹å§‹æ™‚é–“æ¡†æ¶åˆ†æ ===")
        
        # è¼‰å…¥è³‡æ–™
        self.df_1m = self.load_or_fetch_data()
        
        report_rows = []
        
        # æˆæœ¬ï¼ˆå–®é‚Šï¼‰
        cost_one_way = (self.config.taker_fee if self.config.use_taker else self.config.maker_fee) + self.config.slippage_bps / 10000.0
        print(f"æ¡ç”¨ {'åƒå–®' if self.config.use_taker else 'æ›å–®'} è²»ç‡ï¼›å–®é‚Šæˆæœ¬ = {cost_one_way:.6f} ({cost_one_way*100:.4f}%)")
        
        for tf_label, rule in self.config.timeframes.items():
            print(f"\n--- æ™‚é–“æ¡†æ¶ï¼š{tf_label} ({rule}) ---")
            ohlc = self.resample_ohlcv(self.df_1m, rule)
            
            min_bars_required = self.get_min_bars_for_timeframe(tf_label)
            
            if len(ohlc) < min_bars_required:
                min_days_required = self.config.min_days_per_timeframe.get(tf_label, 365) if self.config.use_dynamic_min_bars else "N/A"
                print(f"è³‡æ–™é‡ä¸è¶³ï¼ˆ{len(ohlc)} < {min_bars_required} barsï¼‰ï¼Œç•¥éã€‚")
                if self.config.use_dynamic_min_bars:
                    print(f"  è©²æ™‚é–“æ¡†æ¶éœ€è¦è‡³å°‘ {min_days_required} å¤©çš„è³‡æ–™")
                continue
            
            ann_factor = self.annualization_factor(tf_label)
            
            # C/A
            atr = self.compute_atr(ohlc, self.config.atr_period)
            atr_pct = (atr / ohlc['close']).dropna()
            avg_atr_pct = float(atr_pct.mean()) if len(atr_pct) else np.nan
            cost_roundtrip = 2.0 * cost_one_way
            c_over_a = float(cost_roundtrip / avg_atr_pct) if avg_atr_pct and avg_atr_pct > 0 else np.nan
            
            # VR
            ret = ohlc['close'].pct_change()
            vr = self.variance_ratio(np.log1p(ret), self.config.vr_q)
            
            # åŠè¡°æœŸ
            hl = self.estimate_half_life_by_autocorr(np.log1p(ret), self.config.half_life_max_lag)
            
            # Walk-forward
            ma_oos, ma_param = self.walk_forward_oos(ohlc, "MA", cost_one_way, ann_factor)
            rsi_oos, rsi_param = self.walk_forward_oos(ohlc, "RSI", cost_one_way, ann_factor)
            
            row = {
                "Timeframe": tf_label,
                "Bars": len(ohlc),
                "Avg_ATR_pct": avg_atr_pct,
                "Cost_RoundTrip_pct": cost_roundtrip,
                "C_over_A": c_over_a,
                "VR_q": self.config.vr_q,
                "VarianceRatio": vr,
                "HalfLife_bars": hl,
            }
            
            if ma_oos:
                row.update({f"MA_{k}": v for k, v in ma_oos.items()})
            if rsi_oos:
                row.update({f"RSI_{k}": v for k, v in rsi_oos.items()})
            
            row.update({f"MA_{k}": v for k, v in ma_param.items()} if ma_param else {})
            row.update({f"RSI_{k}": v for k, v in rsi_param.items()} if rsi_param else {})
            
            row["Pass_CA_0.25"] = (c_over_a < 0.25) if not (pd.isna(c_over_a)) else False
            
            report_rows.append(row)
        
        if not report_rows:
            print("æ²’æœ‰å¯ç”¨çš„æ™‚é–“æ¡†æ¶çµæœã€‚è«‹ç¢ºèªè³‡æ–™é‡æˆ–èª¿æ•´æœ€å°è³‡æ–™é‡è¨­å®šã€‚")
            return pd.DataFrame()
        
        report = pd.DataFrame(report_rows).sort_values(
            by=["Pass_CA_0.25", "MA_OOS_Sharpe", "RSI_OOS_Sharpe"],
            ascending=[False, False, False]
        )
        
        return report
    
    def generate_reports(self, report_df: pd.DataFrame) -> None:
        """ç”Ÿæˆå ±å‘Šæª”æ¡ˆ"""
        if report_df.empty:
            print("æ²’æœ‰è³‡æ–™å¯ç”Ÿæˆå ±å‘Š")
            return
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs("./data", exist_ok=True)
        
        # ç”ŸæˆåŒ…å«æ—¥æœŸå€é–“å’Œäº¤æ˜“å°è³‡è¨Šçš„æª”å
        start_date = self.df_1m.index.min().strftime('%Y%m%d')
        end_date = self.df_1m.index.max().strftime('%Y%m%d')
        date_range = f"{start_date}-{end_date}"
        filename_prefix = f"{self.config.symbol.lower()}_{self.config.market_type}_timeframe_report_{date_range}"
        
        # ç”ŸæˆCSVå ±å‘Š
        if self.config.generate_csv_report:
            out_csv = f"./data/{filename_prefix}.csv"
            report_df.to_csv(out_csv, index=False, encoding="utf-8-sig")
            print(f"\nâœ… å·²è¼¸å‡ºCSVå ±è¡¨ï¼š{out_csv}")
        
        # ç”ŸæˆTXTå ±å‘Š
        if self.config.generate_txt_report:
            txt_report = self.generate_txt_report(report_df)
            out_txt = f"./data/{filename_prefix}.txt"
            with open(out_txt, 'w', encoding='utf-8') as f:
                f.write(txt_report)
            print(f"âœ… å·²è¼¸å‡ºTXTå ±è¡¨ï¼š{out_txt}")
        
        print("\nğŸ“‹ å ±å‘Šè§£è®€æŒ‡å—ï¼š")
        print("1) å…ˆçœ‹ C_over_A æ˜¯å¦ < 0.25ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ã€‚")
        print("2) å†çœ‹ç­–ç•¥ OOS_Sharpeï¼ˆè·¨æŠ˜å¹³å‡ï¼‰èˆ‡ OOS_MDDã€‚")
        print("3) VR>1 åè¶¨å‹¢ï¼›VR<1 åå‡å€¼å›æ­¸ï¼›HalfLife æç¤º bar ç²—ç´°ã€‚")
        print("4) è©³ç´°å ±å‘ŠåŒ…å«æ¸¬è©¦æ—¥æœŸç¯„åœã€æˆæœ¬è¨­å®šã€ç­–ç•¥åƒæ•¸ç­‰å®Œæ•´è³‡è¨Šã€‚")
    
    def generate_txt_report(self, report_df: pd.DataFrame) -> str:
        """ç”ŸæˆTXTæ ¼å¼çš„è©³ç´°å ±å‘Š"""
        report = []
        report.append("=" * 80)
        report.append(f"{self.config.symbol} {self.config.market_type.upper()} æ™‚é–“æ¡†æ¶é¸æ“‡åˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # åŸºæœ¬è³‡è¨Š
        report.append("ğŸ“Š åŸºæœ¬è³‡è¨Š")
        report.append("-" * 40)
        report.append(f"äº¤æ˜“å°: {self.config.symbol}")
        report.append(f"å¸‚å ´é¡å‹: {self.config.market_type.upper()}")
        report.append(f"äº¤æ˜“æ‰€: {self.config.exchange.upper()}")
        report.append(f"æ¸¬è©¦æ—¥æœŸç¯„åœ: {self.df_1m.index.min().strftime('%Y-%m-%d %H:%M:%S')} åˆ° {self.df_1m.index.max().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ç¸½æ¸¬è©¦å¤©æ•¸: {(self.df_1m.index.max() - self.df_1m.index.min()).days} å¤©")
        report.append(f"åŸå§‹è³‡æ–™Kç·šæ•¸: {len(self.df_1m):,}")
        report.append(f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æˆæœ¬è¨­å®š
        cost_one_way = (self.config.taker_fee if self.config.use_taker else self.config.maker_fee) + self.config.slippage_bps / 10000.0
        report.append("ğŸ’° æˆæœ¬è¨­å®š")
        report.append("-" * 40)
        report.append(f"è²»ç‡é¡å‹: {'åƒå–®è²»ç‡' if self.config.use_taker else 'æ›å–®è²»ç‡'}")
        report.append(f"å–®é‚Šæˆæœ¬: {cost_one_way:.6f} ({cost_one_way*100:.4f}%)")
        report.append(f"ä¾†å›æˆæœ¬: {cost_one_way*2:.6f} ({cost_one_way*2*100:.4f}%)")
        report.append("")
        
        # æ™‚é–“æ¡†æ¶åˆ†æçµæœ
        report.append("ğŸ“ˆ æ™‚é–“æ¡†æ¶åˆ†æçµæœ")
        report.append("-" * 40)
        report.append("")
        
        tested_timeframes = set(report_df['Timeframe'].tolist())
        
        for tf_label, rule in self.config.timeframes.items():
            if tf_label in tested_timeframes:
                row = report_df[report_df['Timeframe'] == tf_label].iloc[0]
                report.append(f"ğŸ• {row['Timeframe']} æ™‚é–“æ¡†æ¶")
                report.append(f"    Kç·šæ•¸é‡: {row['Bars']:,}")
                report.append(f"    å¹³å‡ATR: {row['Avg_ATR_pct']:.4f} ({row['Avg_ATR_pct']*100:.2f}%)")
                report.append(f"    æˆæœ¬/æ³¢å‹•æ¯” (C/A): {row['C_over_A']:.4f}")
                report.append(f"    èµ°å‹¢ä¸€è‡´æ€§ (VR): {row['VarianceRatio']:.4f}")
                report.append(f"    è¨Šè™ŸåŠè¡°æœŸ: {row['HalfLife_bars']:.1f} bars")
                
                if 'Volatility_Ann' in row and not pd.isna(row['Volatility_Ann']):
                    report.append(f"    å¹´åŒ–æ³¢å‹•ç‡: {row['Volatility_Ann']:.4f}")
                if 'Skewness' in row and not pd.isna(row['Skewness']):
                    report.append(f"    å ±é…¬ååº¦: {row['Skewness']:.4f}")
                if 'Kurtosis' in row and not pd.isna(row['Kurtosis']):
                    report.append(f"    å ±é…¬å³°åº¦: {row['Kurtosis']:.4f}")
                if 'Autocorr_Lag1' in row and not pd.isna(row['Autocorr_Lag1']):
                    report.append(f"    è‡ªç›¸é—œ(Lag1): {row['Autocorr_Lag1']:.4f}")
                if 'Market_Efficiency' in row and not pd.isna(row['Market_Efficiency']):
                    report.append(f"    å¸‚å ´æ•ˆç‡æ¯”ç‡: {row['Market_Efficiency']:.4f}")
                
                if row['Pass_CA_0.25']:
                    report.append(f"    âœ… é€šéC/A < 0.25æ¸¬è©¦")
                else:
                    report.append(f"    âŒ æœªé€šéC/A < 0.25æ¸¬è©¦")
            else:
                report.append(f"ğŸ• {tf_label} æ™‚é–“æ¡†æ¶")
                report.append(f"    âŒ æœªé€²è¡Œæ¸¬è©¦")
                min_bars_required = self.get_min_bars_for_timeframe(tf_label)
                min_days_required = self.config.min_days_per_timeframe.get(tf_label, 365) if self.config.use_dynamic_min_bars else "N/A"
                report.append(f"    åŸå› : è³‡æ–™é‡ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘ {min_bars_required} æ ¹Kç·šï¼‰")
                if self.config.use_dynamic_min_bars:
                    report.append(f"    è¦æ±‚: è‡³å°‘ {min_days_required} å¤©çš„è³‡æ–™")
                report.append(f"    å»ºè­°: å¢åŠ è³‡æ–™å¤©æ•¸æˆ–èª¿æ•´æœ€å°è³‡æ–™é‡è¨­å®š")
            
            report.append("")
        
        # ç¶œåˆå»ºè­°
        report.append("ğŸ’¡ ç¶œåˆå»ºè­°")
        report.append("-" * 40)
        
        best_ca = report_df.loc[report_df['C_over_A'].idxmin()] if 'C_over_A' in report_df.columns else None
        best_vr = report_df.loc[report_df['VarianceRatio'].idxmax()] if 'VarianceRatio' in report_df.columns else None
        
        if best_ca is not None and not pd.isna(best_ca['C_over_A']):
            report.append(f"æœ€ä½³æˆæœ¬æ•ˆç‡æ™‚é–“æ¡†æ¶: {best_ca['Timeframe']} (C/A: {best_ca['C_over_A']:.4f})")
        
        if best_vr is not None and not pd.isna(best_vr['VarianceRatio']):
            report.append(f"æœ€é«˜è¶¨å‹¢æ€§æ™‚é–“æ¡†æ¶: {best_vr['Timeframe']} (VR: {best_vr['VarianceRatio']:.4f})")
        
        report.append("")
        report.append("ğŸ“‹ æŒ‡æ¨™è§£è®€æŒ‡å—:")
        report.append("â€¢ C/A < 0.25: æˆæœ¬ç›¸å°æ–¼æ³¢å‹•ç‡è¼ƒä½ï¼Œé©åˆäº¤æ˜“")
        report.append("â€¢ VR > 1: åè¶¨å‹¢å¸‚å ´ï¼Œé©åˆè¶¨å‹¢ç­–ç•¥")
        report.append("â€¢ VR < 1: åå‡å€¼å›æ­¸å¸‚å ´ï¼Œé©åˆå‡å€¼å›æ­¸ç­–ç•¥")
        report.append("â€¢ åŠè¡°æœŸ: å»ºè­°baré€±æœŸç´„ç‚º0.5~1å€åŠè¡°æœŸ")
        report.append("â€¢ æ³¢å‹•ç‡: åæ˜ å¸‚å ´æ³¢å‹•ç¨‹åº¦")
        report.append("â€¢ ååº¦: æ­£ååº¦è¡¨ç¤ºå³å°¾è¼ƒé•·ï¼Œè² ååº¦è¡¨ç¤ºå·¦å°¾è¼ƒé•·")
        report.append("â€¢ å³°åº¦: é«˜å³°åº¦è¡¨ç¤ºæ¥µç«¯å€¼è¼ƒå¤š")
        report.append("â€¢ è‡ªç›¸é—œ: æ­£å€¼è¡¨ç¤ºè¶¨å‹¢æ€§ï¼Œè² å€¼è¡¨ç¤ºå‡å€¼å›æ­¸")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def analyze(self) -> pd.DataFrame:
        """åŸ·è¡Œå®Œæ•´åˆ†æ"""
        print("=== Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨ ===")
        print(f"åˆ†æäº¤æ˜“å°: {self.config.symbol}")
        print(f"å¸‚å ´é¡å‹: {self.config.market_type.upper()}")
        
        # åˆ†ææ™‚é–“æ¡†æ¶
        report_df = self.analyze_timeframes()
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_reports(report_df)
        
        return report_df


# ä¾¿æ·å‡½æ•¸
def analyze_symbol(symbol: str, market_type: str = "spot", data_days: int = 365) -> pd.DataFrame:
    """åˆ†ææŒ‡å®šäº¤æ˜“å°çš„ä¾¿æ·å‡½æ•¸"""
    config = BinanceAnalyzerConfig(
        symbol=symbol,
        market_type=market_type,
        data_days=data_days
    )
    analyzer = BinanceTimeframeAnalyzer(config)
    return analyzer.analyze()


def get_available_symbols(market_type: str = "spot") -> List[str]:
    """ç²å–å¯ç”¨çš„äº¤æ˜“å°åˆ—è¡¨"""
    return BinanceAPI.get_available_symbols(market_type)


def get_popular_symbols(market_type: str = "spot", limit: int = 50) -> List[str]:
    """ç²å–ç†±é–€äº¤æ˜“å°åˆ—è¡¨"""
    return BinanceAPI.get_popular_symbols(market_type, limit)


if __name__ == "__main__":
    # é è¨­é…ç½® - å¯ä»¥ä¿®æ”¹é€™è£¡ä¾†åˆ†æä¸åŒçš„äº¤æ˜“å°
    config = BinanceAnalyzerConfig(
        symbol="ETHUSDT",
        market_type="spot",  # æˆ– "futures"
        data_days=365
    )
    
    analyzer = BinanceTimeframeAnalyzer(config)
    analyzer.analyze()
