# -*- coding: utf-8 -*-
"""
Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨
æ”¯æ´æ‰€æœ‰ç¾è²¨å’Œæ°¸çºŒåˆç´„äº¤æ˜“å°çš„åˆ†æ
å°ˆæ³¨æ–¼æ™‚é–“æ¡†æ¶ç‰¹æ€§åˆ†æï¼Œä¸åŒ…å«ç­–ç•¥å›æ¸¬åŠŸèƒ½
"""

import math
import warnings
import os
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd

from binance_analyzer_config import BinanceAnalyzerConfig
from binance_api_utils import BinanceAPI

warnings.filterwarnings("ignore")


class BinanceTimeframeAnalyzer:
    """Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨"""
    
    def __init__(self, config: BinanceAnalyzerConfig):
        self.config = config
        self.df_1m = None
    
    def load_or_fetch_data(self) -> pd.DataFrame:
        """è¼‰å…¥æˆ–æŠ“å–è³‡æ–™"""
        if self.config.auto_fetch:
            print("=== è‡ªå‹•æŠ“å–æ¨¡å¼ ===")
            try:
                # é©—è­‰äº¤æ˜“å°
                if not BinanceAPI.validate_symbol(self.config.symbol, self.config.market_type):
                    raise ValueError(f"äº¤æ˜“å° {self.config.symbol} åœ¨ {self.config.market_type} å¸‚å ´ä¸å­˜åœ¨æˆ–ä¸å¯äº¤æ˜“")
                
                self.df_1m = BinanceAPI.fetch_historical_data(
                    self.config.symbol, 
                    self.config.market_type, 
                    self.config.data_days
                )
                
                if self.config.save_csv:
                    self.save_data_to_csv()
                
                return self.df_1m
                
            except Exception as e:
                print(f"è‡ªå‹•æŠ“å–å¤±æ•—: {e}")
                print("å˜—è©¦ä½¿ç”¨æœ¬åœ°CSVæª”æ¡ˆ...")
                return self.load_1m_csv()
        else:
            print("=== æœ¬åœ°CSVæ¨¡å¼ ===")
            return self.load_1m_csv()
    
    def save_data_to_csv(self) -> None:
        """å°‡è³‡æ–™å„²å­˜ç‚º CSV æª”æ¡ˆ"""
        try:
            os.makedirs(os.path.dirname(self.config.csv_path), exist_ok=True)
            self.df_1m.to_csv(self.config.csv_path, encoding='utf-8-sig')
            print(f"è³‡æ–™å·²å„²å­˜è‡³: {self.config.csv_path}")
        except Exception as e:
            print(f"å„²å­˜CSVæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def load_1m_csv(self) -> pd.DataFrame:
        """è®€å– 1m CSV æª”æ¡ˆ"""
        try:
            df = pd.read_csv(self.config.csv_path)
            
            # è½‰æ›æ™‚é–“æˆ³è¨˜
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')
            if df['timestamp'].isna().mean() > 0.5:
                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
            
            # è¨­å®šæ™‚å€
            if df['timestamp'].dt.tz is None:
                df['timestamp'] = df['timestamp'].dt.tz_localize('UTC')
            
            # è½‰æ›è³‡æ–™é¡å‹
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = df[col].astype(float)
            
            df = df.set_index('timestamp').sort_index()
            return df
            
        except Exception as e:
            raise ValueError(f"è®€å–CSVæª”æ¡ˆå¤±æ•—: {e}")
    
    def resample_ohlcv(self, df_1m: pd.DataFrame, rule: str) -> pd.DataFrame:
        """ä»¥ OHLCV è¦å‰‡é‡æ¡æ¨£"""
        agg = {
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum'
        }
        return df_1m.resample(rule, label='right', closed='right').agg(agg).dropna(subset=['open', 'high', 'low', 'close'])
    
    def compute_atr(self, ohlc: pd.DataFrame, period: int = 14) -> pd.Series:
        """è¨ˆç®— ATR (Average True Range)"""
        high = ohlc['high']
        low = ohlc['low']
        close = ohlc['close']
        
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(period).mean()
        
        return atr
    
    def variance_ratio(self, log_returns: pd.Series, q: int) -> float:
        """è¨ˆç®— Variance Ratio (Lo-MacKinlay)"""
        if len(log_returns) < q * 2:
            return np.nan
        
        # ç§»é™¤ NaN
        log_returns = log_returns.dropna()
        if len(log_returns) < q * 2:
            return np.nan
        
        # è¨ˆç®—ä¸åŒæ™‚é–“é–“éš”çš„æ–¹å·®
        var_1 = log_returns.var()
        var_q = log_returns.rolling(q).sum().var()
        
        if var_1 == 0:
            return np.nan
        
        vr = var_q / (q * var_1)
        return float(vr)
    
    def estimate_half_life_by_autocorr(self, log_returns: pd.Series, max_lag: int = 100) -> float:
        """åŸºæ–¼è‡ªç›¸é—œä¼°è¨ˆåŠè¡°æœŸ"""
        if len(log_returns) < max_lag * 2:
            return np.nan
        
        log_returns = log_returns.dropna()
        if len(log_returns) < max_lag * 2:
            return np.nan
        
        # è¨ˆç®—è‡ªç›¸é—œ
        autocorr = []
        for lag in range(1, min(max_lag + 1, len(log_returns) // 2)):
            corr = log_returns.autocorr(lag=lag)
            if not pd.isna(corr):
                autocorr.append((lag, corr))
        
        if len(autocorr) < 3:
            return np.nan
        
        # æ‰¾åˆ°ç¬¬ä¸€å€‹è² è‡ªç›¸é—œ
        for lag, corr in autocorr:
            if corr < 0:
                return float(lag)
        
        # å¦‚æœæ²’æœ‰è² è‡ªç›¸é—œï¼Œè¿”å›æœ€å¤§å»¶é²
        return float(autocorr[-1][0]) if autocorr else np.nan
    
    def get_min_bars_for_timeframe(self, timeframe: str) -> int:
        """ç²å–æ™‚é–“æ¡†æ¶çš„æœ€å° bar æ•¸è¦æ±‚"""
        if not self.config.use_dynamic_min_bars:
            return self.config.n_min_bars_for_backtest
        
        # å‹•æ…‹è¨ˆç®—æœ€å° bar æ•¸
        min_days = self.config.min_days_per_timeframe.get(timeframe, 365)
        
        # æ ¹æ“šæ™‚é–“æ¡†æ¶è¨ˆç®—å°æ‡‰çš„ bar æ•¸
        timeframe_minutes = {
            "1m": 1,
            "5m": 5,
            "15m": 15,
            "1h": 60,
            "4h": 240,
            "1d": 1440,
            "1w": 10080
        }
        
        minutes_per_bar = timeframe_minutes.get(timeframe, 1440)
        min_bars = int(min_days * 24 * 60 / minutes_per_bar)
        
        return max(min_bars, 100)  # è‡³å°‘éœ€è¦ 100 æ ¹ bar
    
    def annualization_factor(self, timeframe: str) -> float:
        """è¨ˆç®—å¹´åŒ–å› å­"""
        timeframe_minutes = {
            "1m": 1,
            "5m": 5,
            "15m": 15,
            "1h": 60,
            "4h": 240,
            "1d": 1440,
            "1w": 10080
        }
        
        minutes_per_bar = timeframe_minutes.get(timeframe, 1440)
        minutes_per_year = 365 * 24 * 60
        
        return minutes_per_year / minutes_per_bar
    
    def calculate_volatility(self, returns: pd.Series, ann_factor: float) -> float:
        """è¨ˆç®—å¹´åŒ–æ³¢å‹•ç‡"""
        if len(returns) < 2:
            return np.nan
        return float(returns.std() * np.sqrt(ann_factor))
    
    def calculate_skewness(self, returns: pd.Series) -> float:
        """è¨ˆç®—å ±é…¬ååº¦"""
        if len(returns) < 3:
            return np.nan
        return float(returns.skew())
    
    def calculate_kurtosis(self, returns: pd.Series) -> float:
        """è¨ˆç®—å ±é…¬å³°åº¦"""
        if len(returns) < 4:
            return np.nan
        return float(returns.kurtosis())
    
    def calculate_autocorrelation(self, returns: pd.Series, lag: int = 1) -> float:
        """è¨ˆç®—å ±é…¬è‡ªç›¸é—œ"""
        if len(returns) < lag + 1:
            return np.nan
        return float(returns.autocorr(lag=lag))
    
    def calculate_market_efficiency_ratio(self, log_returns: pd.Series, q: int = 4) -> float:
        """è¨ˆç®—å¸‚å ´æ•ˆç‡æ¯”ç‡ï¼ˆåŸºæ–¼æ–¹å·®æ¯”ï¼‰"""
        vr = self.variance_ratio(log_returns, q)
        if pd.isna(vr):
            return np.nan
        # å¸‚å ´æ•ˆç‡æ¯”ç‡ = 1 / VRï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºè¶Šæœ‰æ•ˆç‡
        return float(1.0 / vr) if vr > 0 else np.nan
    
    def analyze_timeframes(self) -> pd.DataFrame:
        """åˆ†ææ‰€æœ‰æ™‚é–“æ¡†æ¶"""
        print("=== é–‹å§‹æ™‚é–“æ¡†æ¶åˆ†æ ===")
        
        # è¼‰å…¥è³‡æ–™
        self.df_1m = self.load_or_fetch_data()
        
        report_rows = []
        
        # æˆæœ¬ï¼ˆå–®é‚Šï¼‰
        cost_one_way = (self.config.taker_fee if self.config.use_taker else self.config.maker_fee) + self.config.slippage_bps / 10000.0
        print(f"æ¡ç”¨ {'åƒå–®' if self.config.use_taker else 'æ›å–®'} è²»ç‡ï¼›å–®é‚Šæˆæœ¬ = {cost_one_way:.6f} ({cost_one_way*100:.4f}%)")
        
        for tf_label, rule in self.config.timeframes.items():
            print(f"\n--- æ™‚é–“æ¡†æ¶ï¼š{tf_label} ({rule}) ---")
            ohlc = self.resample_ohlcv(self.df_1m, rule)
            
            min_bars_required = self.get_min_bars_for_timeframe(tf_label)
            
            if len(ohlc) < min_bars_required:
                min_days_required = self.config.min_days_per_timeframe.get(tf_label, 365) if self.config.use_dynamic_min_bars else "N/A"
                print(f"è³‡æ–™é‡ä¸è¶³ï¼ˆ{len(ohlc)} < {min_bars_required} barsï¼‰ï¼Œç•¥éã€‚")
                if self.config.use_dynamic_min_bars:
                    print(f"  è©²æ™‚é–“æ¡†æ¶éœ€è¦è‡³å°‘ {min_days_required} å¤©çš„è³‡æ–™")
                continue
            
            ann_factor = self.annualization_factor(tf_label)
            
            # C/A
            atr = self.compute_atr(ohlc, self.config.atr_period)
            atr_pct = (atr / ohlc['close']).dropna()
            avg_atr_pct = float(atr_pct.mean()) if len(atr_pct) else np.nan
            cost_roundtrip = 2.0 * cost_one_way
            c_over_a = float(cost_roundtrip / avg_atr_pct) if avg_atr_pct and avg_atr_pct > 0 else np.nan
            
            # VR
            ret = ohlc['close'].pct_change()
            vr = self.variance_ratio(np.log1p(ret), self.config.vr_q)
            
            # åŠè¡°æœŸ
            hl = self.estimate_half_life_by_autocorr(np.log1p(ret), self.config.half_life_max_lag)
            
            # æ–°å¢æŠ€è¡“æŒ‡æ¨™
            log_returns = np.log1p(ret).dropna()
            volatility_ann = self.calculate_volatility(ret.dropna(), ann_factor)
            skewness = self.calculate_skewness(ret.dropna())
            kurtosis = self.calculate_kurtosis(ret.dropna())
            autocorr_lag1 = self.calculate_autocorrelation(ret.dropna(), 1)
            market_efficiency = self.calculate_market_efficiency_ratio(log_returns, self.config.vr_q)
            
            row = {
                "Timeframe": tf_label,
                "Bars": len(ohlc),
                "Avg_ATR_pct": avg_atr_pct,
                "Cost_RoundTrip_pct": cost_roundtrip,
                "C_over_A": c_over_a,
                "VR_q": self.config.vr_q,
                "VarianceRatio": vr,
                "HalfLife_bars": hl,
                "Volatility_Ann": volatility_ann,
                "Skewness": skewness,
                "Kurtosis": kurtosis,
                "Autocorr_Lag1": autocorr_lag1,
                "Market_Efficiency": market_efficiency
            }
            
            row["Pass_CA_0.25"] = (c_over_a < 0.25) if not (pd.isna(c_over_a)) else False
            
            report_rows.append(row)
        
        if not report_rows:
            print("æ²’æœ‰å¯ç”¨çš„æ™‚é–“æ¡†æ¶çµæœã€‚è«‹ç¢ºèªè³‡æ–™é‡æˆ–èª¿æ•´æœ€å°è³‡æ–™é‡è¨­å®šã€‚")
            return pd.DataFrame()
        
        report = pd.DataFrame(report_rows).sort_values(
            by=["Pass_CA_0.25", "C_over_A"],
            ascending=[False, True]
        )
        
        return report
    
    def generate_reports(self, report_df: pd.DataFrame) -> None:
        """ç”Ÿæˆå ±å‘Šæª”æ¡ˆ"""
        if report_df.empty:
            print("æ²’æœ‰è³‡æ–™å¯ç”Ÿæˆå ±å‘Š")
            return
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs("./data", exist_ok=True)
        
        # ç”ŸæˆåŒ…å«æ—¥æœŸå€é–“å’Œäº¤æ˜“å°è³‡è¨Šçš„æª”å
        start_date = self.df_1m.index.min().strftime('%Y%m%d')
        end_date = self.df_1m.index.max().strftime('%Y%m%d')
        date_range = f"{start_date}-{end_date}"
        filename_prefix = f"{self.config.symbol.lower()}_{self.config.market_type}_timeframe_report_{date_range}"
        
        # ç”ŸæˆCSVå ±å‘Š
        if self.config.generate_csv_report:
            out_csv = f"./data/{filename_prefix}.csv"
            report_df.to_csv(out_csv, index=False, encoding="utf-8-sig")
            print(f"\nâœ… å·²è¼¸å‡ºCSVå ±è¡¨ï¼š{out_csv}")
        
        # ç”ŸæˆTXTå ±å‘Š
        if self.config.generate_txt_report:
            txt_report = self.generate_txt_report(report_df)
            out_txt = f"./data/{filename_prefix}.txt"
            with open(out_txt, 'w', encoding='utf-8') as f:
                f.write(txt_report)
            print(f"âœ… å·²è¼¸å‡ºTXTå ±è¡¨ï¼š{out_txt}")
        
        # ç”ŸæˆMDå ±å‘Š
        if self.config.generate_md_report:
            md_report = self.generate_md_report(report_df)
            out_md = f"./data/{filename_prefix}.md"
            with open(out_md, 'w', encoding='utf-8') as f:
                f.write(md_report)
            print(f"âœ… å·²è¼¸å‡ºMDå ±è¡¨ï¼š{out_md}")
        
        print("\nğŸ“‹ å ±å‘Šè§£è®€æŒ‡å—ï¼š")
        print("1) å…ˆçœ‹ C_over_A æ˜¯å¦ < 0.25ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ã€‚")
        print("2) å†çœ‹ VarianceRatio åˆ¤æ–·å¸‚å ´ç‰¹æ€§ï¼ˆ>1åè¶¨å‹¢ï¼Œ<1åå‡å€¼å›æ­¸ï¼‰ã€‚")
        print("3) åŠè¡°æœŸæç¤º bar ç²—ç´°ï¼Œå»ºè­°baré€±æœŸç´„ç‚º0.5~1å€åŠè¡°æœŸã€‚")
        print("4) æŠ€è¡“æŒ‡æ¨™å¹«åŠ©äº†è§£å¸‚å ´çµ±è¨ˆç‰¹æ€§ã€‚")
    
    def generate_txt_report(self, report_df: pd.DataFrame) -> str:
        """ç”ŸæˆTXTæ ¼å¼çš„è©³ç´°å ±å‘Š"""
        report = []
        report.append("=" * 80)
        report.append(f"{self.config.symbol} {self.config.market_type.upper()} æ™‚é–“æ¡†æ¶é¸æ“‡åˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # åŸºæœ¬è³‡è¨Š
        report.append("ğŸ“Š åŸºæœ¬è³‡è¨Š")
        report.append("-" * 40)
        report.append(f"äº¤æ˜“å°: {self.config.symbol}")
        report.append(f"å¸‚å ´é¡å‹: {self.config.market_type.upper()}")
        report.append(f"äº¤æ˜“æ‰€: {self.config.exchange.upper()}")
        report.append(f"æ¸¬è©¦æ—¥æœŸç¯„åœ: {self.df_1m.index.min().strftime('%Y-%m-%d %H:%M:%S')} åˆ° {self.df_1m.index.max().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ç¸½æ¸¬è©¦å¤©æ•¸: {(self.df_1m.index.max() - self.df_1m.index.min()).days} å¤©")
        report.append(f"åŸå§‹è³‡æ–™Kç·šæ•¸: {len(self.df_1m):,}")
        report.append(f"å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æˆæœ¬è¨­å®š
        cost_one_way = (self.config.taker_fee if self.config.use_taker else self.config.maker_fee) + self.config.slippage_bps / 10000.0
        report.append("ğŸ’° æˆæœ¬è¨­å®š")
        report.append("-" * 40)
        report.append(f"è²»ç‡é¡å‹: {'åƒå–®è²»ç‡' if self.config.use_taker else 'æ›å–®è²»ç‡'}")
        report.append(f"å–®é‚Šæˆæœ¬: {cost_one_way:.6f} ({cost_one_way*100:.4f}%)")
        report.append(f"ä¾†å›æˆæœ¬: {cost_one_way*2:.6f} ({cost_one_way*2*100:.4f}%)")
        report.append("")
        
        # åˆ†æè¨­å®š
        report.append("âš™ï¸ åˆ†æè¨­å®š")
        report.append("-" * 40)
        report.append(f"ATRè¨ˆç®—é€±æœŸ: {self.config.atr_period}")
        report.append(f"Variance Ratioèšåˆå°ºåº¦: {self.config.vr_q}")
        report.append(f"åŠè¡°æœŸè¨ˆç®—æœ€å¤§å»¶é²: {self.config.half_life_max_lag}")
        report.append(f"å‹•æ…‹æœ€å°è³‡æ–™é‡: {'å•Ÿç”¨' if self.config.use_dynamic_min_bars else 'åœç”¨'}")
        report.append("")
        
        # æ™‚é–“æ¡†æ¶åˆ†æçµæœ
        report.append("ğŸ“ˆ æ™‚é–“æ¡†æ¶åˆ†æçµæœ")
        report.append("-" * 40)
        report.append("")
        
        tested_timeframes = set(report_df['Timeframe'].tolist())
        
        for tf_label, rule in self.config.timeframes.items():
            if tf_label in tested_timeframes:
                row = report_df[report_df['Timeframe'] == tf_label].iloc[0]
                report.append(f"ğŸ• {row['Timeframe']} æ™‚é–“æ¡†æ¶")
                report.append(f"    Kç·šæ•¸é‡: {row['Bars']:,}")
                report.append(f"    å¹³å‡ATR: {row['Avg_ATR_pct']:.4f} ({row['Avg_ATR_pct']*100:.2f}%)")
                report.append(f"    æˆæœ¬/æ³¢å‹•æ¯” (C/A): {row['C_over_A']:.4f}")
                report.append(f"    èµ°å‹¢ä¸€è‡´æ€§ (VR): {row['VarianceRatio']:.4f}")
                report.append(f"    è¨Šè™ŸåŠè¡°æœŸ: {row['HalfLife_bars']:.1f} bars")
                
                if 'Volatility_Ann' in row and not pd.isna(row['Volatility_Ann']):
                    report.append(f"    å¹´åŒ–æ³¢å‹•ç‡: {row['Volatility_Ann']:.4f}")
                if 'Skewness' in row and not pd.isna(row['Skewness']):
                    report.append(f"    å ±é…¬ååº¦: {row['Skewness']:.4f}")
                if 'Kurtosis' in row and not pd.isna(row['Kurtosis']):
                    report.append(f"    å ±é…¬å³°åº¦: {row['Kurtosis']:.4f}")
                if 'Autocorr_Lag1' in row and not pd.isna(row['Autocorr_Lag1']):
                    report.append(f"    è‡ªç›¸é—œ(Lag1): {row['Autocorr_Lag1']:.4f}")
                if 'Market_Efficiency' in row and not pd.isna(row['Market_Efficiency']):
                    report.append(f"    å¸‚å ´æ•ˆç‡æ¯”ç‡: {row['Market_Efficiency']:.4f}")
                
                if row['Pass_CA_0.25']:
                    report.append(f"    âœ… é€šéC/A < 0.25æ¸¬è©¦")
                else:
                    report.append(f"    âŒ æœªé€šéC/A < 0.25æ¸¬è©¦")
            else:
                report.append(f"ğŸ• {tf_label} æ™‚é–“æ¡†æ¶")
                report.append(f"    âŒ æœªé€²è¡Œæ¸¬è©¦")
                min_bars_required = self.get_min_bars_for_timeframe(tf_label)
                min_days_required = self.config.min_days_per_timeframe.get(tf_label, 365) if self.config.use_dynamic_min_bars else "N/A"
                report.append(f"    åŸå› : è³‡æ–™é‡ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘ {min_bars_required} æ ¹Kç·šï¼‰")
                if self.config.use_dynamic_min_bars:
                    report.append(f"    è¦æ±‚: è‡³å°‘ {min_days_required} å¤©çš„è³‡æ–™")
                report.append(f"    å»ºè­°: å¢åŠ è³‡æ–™å¤©æ•¸æˆ–èª¿æ•´æœ€å°è³‡æ–™é‡è¨­å®š")
            
            report.append("")
        
        # ç¶œåˆå»ºè­°
        report.append("ğŸ’¡ ç¶œåˆå»ºè­°")
        report.append("-" * 40)
        
        best_ca = report_df.loc[report_df['C_over_A'].idxmin()] if 'C_over_A' in report_df.columns else None
        best_vr = report_df.loc[report_df['VarianceRatio'].idxmax()] if 'VarianceRatio' in report_df.columns else None
        
        if best_ca is not None and not pd.isna(best_ca['C_over_A']):
            report.append(f"æœ€ä½³æˆæœ¬æ•ˆç‡æ™‚é–“æ¡†æ¶: {best_ca['Timeframe']} (C/A: {best_ca['C_over_A']:.4f})")
        
        if best_vr is not None and not pd.isna(best_vr['VarianceRatio']):
            report.append(f"æœ€é«˜è¶¨å‹¢æ€§æ™‚é–“æ¡†æ¶: {best_vr['Timeframe']} (VR: {best_vr['VarianceRatio']:.4f})")
        
        report.append("")
        report.append("ğŸ“‹ æŒ‡æ¨™è§£è®€æŒ‡å—:")
        report.append("â€¢ C/A < 0.25: æˆæœ¬ç›¸å°æ–¼æ³¢å‹•ç‡è¼ƒä½ï¼Œé©åˆäº¤æ˜“")
        report.append("â€¢ VR > 1: åè¶¨å‹¢å¸‚å ´ï¼Œé©åˆè¶¨å‹¢ç­–ç•¥")
        report.append("â€¢ VR < 1: åå‡å€¼å›æ­¸å¸‚å ´ï¼Œé©åˆå‡å€¼å›æ­¸ç­–ç•¥")
        report.append("â€¢ åŠè¡°æœŸ: å»ºè­°baré€±æœŸç´„ç‚º0.5~1å€åŠè¡°æœŸ")
        report.append("â€¢ æ³¢å‹•ç‡: åæ˜ å¸‚å ´æ³¢å‹•ç¨‹åº¦")
        report.append("â€¢ ååº¦: æ­£ååº¦è¡¨ç¤ºå³å°¾è¼ƒé•·ï¼Œè² ååº¦è¡¨ç¤ºå·¦å°¾è¼ƒé•·")
        report.append("â€¢ å³°åº¦: é«˜å³°åº¦è¡¨ç¤ºæ¥µç«¯å€¼è¼ƒå¤š")
        report.append("â€¢ è‡ªç›¸é—œ: æ­£å€¼è¡¨ç¤ºè¶¨å‹¢æ€§ï¼Œè² å€¼è¡¨ç¤ºå‡å€¼å›æ­¸")
        report.append("â€¢ å¸‚å ´æ•ˆç‡æ¯”ç‡: è¶Šæ¥è¿‘1è¡¨ç¤ºå¸‚å ´è¶Šæœ‰æ•ˆç‡")
        
        # æ·»åŠ è©³ç´°æŒ‡æ¨™è§£é‡‹
        report.append("")
        report.append("ğŸ“Š è©³ç´°æŒ‡æ¨™è§£é‡‹")
        report.append("-" * 40)
        report.append("")
        
        report.append("ğŸ” æˆæœ¬/æ³¢å‹•æ¯” (C/A Ratio)")
        report.append("æ„ç¾©: è¡¡é‡äº¤æ˜“æˆæœ¬ç›¸å°æ–¼å¸‚å ´æ³¢å‹•çš„æ¯”ç‡")
        report.append("è§£è®€: ")
        report.append("â€¢ C/A < 0.25: æˆæœ¬ç›¸å°è¼ƒä½ï¼Œé©åˆé »ç¹äº¤æ˜“")
        report.append("â€¢ C/A 0.25-0.5: æˆæœ¬é©ä¸­ï¼Œéœ€è¦è¬¹æ…é¸æ“‡å…¥å ´é»")
        report.append("â€¢ C/A > 0.5: æˆæœ¬éé«˜ï¼Œä¸é©åˆçŸ­ç·šäº¤æ˜“")
        report.append("")
        
        report.append("ğŸ” èµ°å‹¢ä¸€è‡´æ€§ (Variance Ratio, VR)")
        report.append("æ„ç¾©: è¡¡é‡åƒ¹æ ¼è®Šå‹•çš„è¶¨å‹¢æ€§å¼·åº¦")
        report.append("è§£è®€:")
        report.append("â€¢ VR > 1: åƒ¹æ ¼è®Šå‹•å…·æœ‰è¶¨å‹¢æ€§ï¼Œé©åˆè¶¨å‹¢è·Ÿéš¨ç­–ç•¥")
        report.append("â€¢ VR < 1: åƒ¹æ ¼è®Šå‹•åå‘éš¨æ©ŸéŠèµ°ï¼Œé©åˆå‡å€¼å›æ­¸ç­–ç•¥")
        report.append("â€¢ VR â‰ˆ 1: åƒ¹æ ¼è®Šå‹•æ¥è¿‘éš¨æ©ŸéŠèµ°")
        report.append("")
        
        report.append("ğŸ” è¨Šè™ŸåŠè¡°æœŸ (Signal Half-Life)")
        report.append("æ„ç¾©: è¡¡é‡åƒ¹æ ¼è¨Šè™Ÿçš„æŒçºŒæ™‚é–“")
        report.append("è§£è®€:")
        report.append("â€¢ åŠè¡°æœŸè¶Šé•·ï¼Œè¨Šè™Ÿè¶ŠæŒä¹…ï¼Œé©åˆè¼ƒé•·æœŸçš„ç­–ç•¥")
        report.append("â€¢ åŠè¡°æœŸè¶ŠçŸ­ï¼Œè¨Šè™Ÿè®ŠåŒ–è¶Šå¿«ï¼Œéœ€è¦æ›´é »ç¹çš„èª¿æ•´")
        report.append("")
        
        report.append("ğŸ” å¹´åŒ–æ³¢å‹•ç‡ (Annualized Volatility)")
        report.append("æ„ç¾©: è¡¡é‡åƒ¹æ ¼è®Šå‹•çš„åŠ‡çƒˆç¨‹åº¦")
        report.append("è§£è®€:")
        report.append("â€¢ æ³¢å‹•ç‡è¶Šé«˜ï¼Œåƒ¹æ ¼è®Šå‹•è¶ŠåŠ‡çƒˆï¼Œé¢¨éšªè¶Šå¤§")
        report.append("â€¢ æ³¢å‹•ç‡è¶Šä½ï¼Œåƒ¹æ ¼è®Šå‹•è¶Šå¹³ç©©ï¼Œé¢¨éšªè¼ƒå°")
        report.append("")
        
        report.append("ğŸ” å ±é…¬ååº¦ (Return Skewness)")
        report.append("æ„ç¾©: è¡¡é‡å ±é…¬åˆ†å¸ƒçš„å°ç¨±æ€§")
        report.append("è§£è®€:")
        report.append("â€¢ æ­£ååº¦: å³å°¾è¼ƒé•·ï¼Œå¤§å¹…ä¸Šæ¼²æ©Ÿç‡è¼ƒé«˜")
        report.append("â€¢ è² ååº¦: å·¦å°¾è¼ƒé•·ï¼Œå¤§å¹…ä¸‹è·Œæ©Ÿç‡è¼ƒé«˜")
        report.append("")
        
        report.append("ğŸ” å ±é…¬å³°åº¦ (Return Kurtosis)")
        report.append("æ„ç¾©: è¡¡é‡å ±é…¬åˆ†å¸ƒçš„å°–éŠ³ç¨‹åº¦")
        report.append("è§£è®€:")
        report.append("â€¢ é«˜å³°åº¦: æ¥µç«¯å€¼å‡ºç¾æ©Ÿç‡è¼ƒé«˜ï¼Œé¢¨éšªè¼ƒå¤§")
        report.append("â€¢ ä½å³°åº¦: åˆ†å¸ƒè¼ƒå¹³å¦ï¼Œæ¥µç«¯å€¼è¼ƒå°‘")
        report.append("")
        
        report.append("ğŸ” è‡ªç›¸é—œ (Autocorrelation)")
        report.append("æ„ç¾©: è¡¡é‡ç•¶å‰åƒ¹æ ¼èˆ‡éå»åƒ¹æ ¼çš„ç›¸é—œæ€§")
        report.append("è§£è®€:")
        report.append("â€¢ æ­£å€¼: åƒ¹æ ¼å…·æœ‰è¶¨å‹¢æ€§ï¼Œéå»èµ°å‹¢å°æœªä¾†æœ‰å½±éŸ¿")
        report.append("â€¢ è² å€¼: åƒ¹æ ¼å…·æœ‰å‡å€¼å›æ­¸ç‰¹æ€§")
        report.append("")
        
        report.append("ğŸ” å¸‚å ´æ•ˆç‡æ¯”ç‡ (Market Efficiency Ratio)")
        report.append("æ„ç¾©: è¡¡é‡å¸‚å ´çš„è³‡è¨Šæ•ˆç‡")
        report.append("è§£è®€:")
        report.append("â€¢ æ¥è¿‘1: å¸‚å ´æ•ˆç‡è¼ƒé«˜ï¼Œåƒ¹æ ¼å……åˆ†åæ˜ è³‡è¨Š")
        report.append("â€¢ é é›¢1: å¸‚å ´æ•ˆç‡è¼ƒä½ï¼Œå¯èƒ½å­˜åœ¨å¥—åˆ©æ©Ÿæœƒ")
        report.append("")
        
        # æ·»åŠ å¸‚å ´åˆ†æçµè«–
        report.append("ğŸ“ˆ å¸‚å ´åˆ†æçµè«–")
        report.append("-" * 40)
        report.append("")
        
        # åˆ†ææ•´é«”å¸‚å ´ç‰¹æ€§
        avg_volatility = report_df['Volatility_Ann'].mean() if 'Volatility_Ann' in report_df.columns else None
        avg_vr = report_df['VarianceRatio'].mean() if 'VarianceRatio' in report_df.columns else None
        avg_autocorr = report_df['Autocorr_Lag1'].mean() if 'Autocorr_Lag1' in report_df.columns else None
        avg_me = report_df['Market_Efficiency'].mean() if 'Market_Efficiency' in report_df.columns else None
        
        report.append("ğŸ¯ æ•´é«”å¸‚å ´ç‰¹æ€§:")
        if avg_volatility and not pd.isna(avg_volatility):
            volatility_level = "é«˜" if avg_volatility > 0.5 else "ä¸­" if avg_volatility > 0.3 else "ä½"
            report.append(f"1. æ³¢å‹•æ€§: {self.config.symbol} {self.config.market_type}å¹´åŒ–æ³¢å‹•ç‡ç´„{avg_volatility:.1%}ï¼Œå±¬æ–¼{volatility_level}æ³¢å‹•è³‡ç”¢")
        
        if avg_me and not pd.isna(avg_me):
            efficiency_level = "é«˜" if abs(avg_me - 1) < 0.1 else "ä¸­" if abs(avg_me - 1) < 0.2 else "ä½"
            report.append(f"2. å¸‚å ´æ•ˆç‡: å„æ™‚é–“æ¡†æ¶çš„å¸‚å ´æ•ˆç‡æ¯”ç‡éƒ½æ¥è¿‘1ï¼Œé¡¯ç¤ºå¸‚å ´è³‡è¨Šæ•ˆç‡è¼ƒ{efficiency_level}")
        
        if avg_autocorr and not pd.isna(avg_autocorr):
            if avg_autocorr < -0.01:
                report.append("3. å‡å€¼å›æ­¸: å¤§éƒ¨åˆ†æ™‚é–“æ¡†æ¶é¡¯ç¤ºè² è‡ªç›¸é—œï¼Œè¡¨ç¤ºåƒ¹æ ¼å…·æœ‰å‡å€¼å›æ­¸ç‰¹æ€§")
            elif avg_autocorr > 0.01:
                report.append("3. è¶¨å‹¢æ€§: å¤§éƒ¨åˆ†æ™‚é–“æ¡†æ¶é¡¯ç¤ºæ­£è‡ªç›¸é—œï¼Œè¡¨ç¤ºåƒ¹æ ¼å…·æœ‰è¶¨å‹¢æ€§")
            else:
                report.append("3. éš¨æ©Ÿæ€§: å¤§éƒ¨åˆ†æ™‚é–“æ¡†æ¶é¡¯ç¤ºæ¥è¿‘é›¶çš„è‡ªç›¸é—œï¼Œè¡¨ç¤ºåƒ¹æ ¼è®Šå‹•æ¥è¿‘éš¨æ©Ÿ")
        
        # åˆ†æååº¦ç‰¹æ€§
        long_term_timeframes = ['1d', '1w']
        long_term_skewness = []
        for tf in long_term_timeframes:
            if tf in report_df['Timeframe'].values:
                row = report_df[report_df['Timeframe'] == tf].iloc[0]
                if 'Skewness' in row and not pd.isna(row['Skewness']):
                    long_term_skewness.append(row['Skewness'])
        
        if long_term_skewness:
            avg_long_skew = sum(long_term_skewness) / len(long_term_skewness)
            if avg_long_skew > 0.1:
                report.append("4. é•·æœŸæ­£ååº¦: è¼ƒé•·æ™‚é–“æ¡†æ¶é¡¯ç¤ºæ­£ååº¦ï¼Œé•·æœŸä¾†çœ‹ä¸Šæ¼²æ©Ÿç‡è¼ƒé«˜")
            elif avg_long_skew < -0.1:
                report.append("4. é•·æœŸè² ååº¦: è¼ƒé•·æ™‚é–“æ¡†æ¶é¡¯ç¤ºè² ååº¦ï¼Œé•·æœŸä¾†çœ‹ä¸‹è·Œæ©Ÿç‡è¼ƒé«˜")
            else:
                report.append("4. é•·æœŸå°ç¨±æ€§: è¼ƒé•·æ™‚é–“æ¡†æ¶é¡¯ç¤ºæ¥è¿‘å°ç¨±çš„åˆ†å¸ƒ")
        
        report.append("")
        report.append("ğŸ¯ äº¤æ˜“ç­–ç•¥å»ºè­°:")
        
        # åˆ†æé€šéC/Aæ¸¬è©¦çš„æ™‚é–“æ¡†æ¶
        passed_timeframes = report_df[report_df['Pass_CA_0.25'] == True]['Timeframe'].tolist()
        short_timeframes = [tf for tf in passed_timeframes if tf in ['1m', '5m', '15m']]
        medium_timeframes = [tf for tf in passed_timeframes if tf in ['1h', '4h']]
        long_timeframes = [tf for tf in passed_timeframes if tf in ['1d', '1w']]
        
        if short_timeframes:
            report.append(f"1. çŸ­ç·šäº¤æ˜“({', '.join(short_timeframes)}): é©åˆï¼Œæˆæœ¬æ•ˆç‡è¼ƒå¥½")
        else:
            report.append("1. çŸ­ç·šäº¤æ˜“(1m-15m): ä¸å»ºè­°ï¼Œå› ç‚ºäº¤æ˜“æˆæœ¬ç›¸å°æ³¢å‹•ç‡éé«˜(C/A > 0.25)")
        
        if medium_timeframes:
            report.append(f"2. ä¸­ç·šäº¤æ˜“({', '.join(medium_timeframes)}): é©åˆï¼Œæˆæœ¬æ•ˆç‡è¼ƒå¥½")
        
        if long_timeframes:
            report.append(f"3. é•·ç·šäº¤æ˜“({', '.join(long_timeframes)}): æœ€é©åˆï¼Œæˆæœ¬æ•ˆç‡æœ€ä½³ï¼Œé©åˆè¶¨å‹¢è·Ÿéš¨ç­–ç•¥")
        
        report.append("")
        report.append("ğŸ¯ é¢¨éšªç®¡ç†å»ºè­°:")
        report.append("1. ç”±æ–¼é«˜æ³¢å‹•æ€§ï¼Œå»ºè­°ä½¿ç”¨è¼ƒå°çš„å€‰ä½è¦æ¨¡")
        report.append("2. è¨­ç½®é©ç•¶çš„æ­¢æä½ï¼Œé¿å…æ¥µç«¯åƒ¹æ ¼è®Šå‹•é€ æˆçš„æå¤±")
        report.append("3. è€ƒæ…®ä½¿ç”¨æœŸæ¬Šç­‰è¡ç”Ÿå“é€²è¡Œé¢¨éšªå°æ²–")
        report.append("4. é—œæ³¨å¸‚å ´æƒ…ç·’æŒ‡æ¨™ï¼Œé¿å…åœ¨æ¥µç«¯å¸‚å ´æ¢ä»¶ä¸‹äº¤æ˜“")
        
        report.append("")
        report.append("ğŸ¯ æœ€ä½³æ™‚é–“æ¡†æ¶é¸æ“‡:")
        
        # æ‰¾å‡ºæœ€ä½³æ™‚é–“æ¡†æ¶
        if best_ca is not None and not pd.isna(best_ca['C_over_A']):
            if best_ca['Timeframe'] in ['1h', '4h']:
                report.append(f"â€¢ æ—¥å…§äº¤æ˜“: {best_ca['Timeframe']}æ™‚é–“æ¡†æ¶ (C/A: {best_ca['C_over_A']:.4f})")
            elif best_ca['Timeframe'] in ['1d', '1w']:
                report.append(f"â€¢ é•·æœŸæŠ•è³‡: {best_ca['Timeframe']}æ™‚é–“æ¡†æ¶ (C/A: {best_ca['C_over_A']:.4f}ï¼Œæˆæœ¬æ•ˆç‡æœ€ä½³)")
        
        if best_vr is not None and not pd.isna(best_vr['VarianceRatio']):
            if best_vr['VarianceRatio'] > 1.05:
                report.append(f"â€¢ æ³¢æ®µäº¤æ˜“: {best_vr['Timeframe']}æ™‚é–“æ¡†æ¶ (VR: {best_vr['VarianceRatio']:.4f}ï¼Œè¶¨å‹¢æ€§æœ€å¼·)")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def generate_md_report(self, report_df: pd.DataFrame) -> str:
        """ç”ŸæˆMarkdownæ ¼å¼çš„è©³ç´°å ±å‘Š"""
        report = []
        report.append(f"# {self.config.symbol} æ™‚é–“æ¡†æ¶é¸æ“‡åˆ†æå ±å‘Š")
        report.append("")
        report.append(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # åŸºæœ¬è³‡è¨Š
        report.append("## ğŸ“Š åŸºæœ¬è³‡è¨Š")
        report.append("")
        report.append("| é …ç›® | æ•¸å€¼ |")
        report.append("|------|------|")
        report.append(f"| äº¤æ˜“å° | {self.config.symbol} |")
        report.append(f"| å¸‚å ´é¡å‹ | {self.config.market_type.upper()} |")
        report.append(f"| äº¤æ˜“æ‰€ | {self.config.exchange.upper()} |")
        report.append(f"| æ¸¬è©¦é–‹å§‹æ™‚é–“ | {self.df_1m.index.min().strftime('%Y-%m-%d %H:%M:%S')} |")
        report.append(f"| æ¸¬è©¦çµæŸæ™‚é–“ | {self.df_1m.index.max().strftime('%Y-%m-%d %H:%M:%S')} |")
        report.append(f"| ç¸½æ¸¬è©¦å¤©æ•¸ | {(self.df_1m.index.max() - self.df_1m.index.min()).days} å¤© |")
        report.append(f"| åŸå§‹è³‡æ–™Kç·šæ•¸ | {len(self.df_1m):,} |")
        report.append("")
        
        # æˆæœ¬è¨­å®š
        cost_one_way = (self.config.taker_fee if self.config.use_taker else self.config.maker_fee) + self.config.slippage_bps / 10000.0
        report.append("## ğŸ’° æˆæœ¬è¨­å®š")
        report.append("")
        report.append("| é …ç›® | æ•¸å€¼ |")
        report.append("|------|------|")
        report.append(f"| è²»ç‡é¡å‹ | {'åƒå–®è²»ç‡' if self.config.use_taker else 'æ›å–®è²»ç‡'} |")
        report.append(f"| å–®é‚Šæˆæœ¬ | {cost_one_way:.6f} ({cost_one_way*100:.4f}%) |")
        report.append(f"| ä¾†å›æˆæœ¬ | {cost_one_way*2:.6f} ({cost_one_way*2*100:.4f}%) |")
        report.append("")
        
        # åˆ†æè¨­å®š
        report.append("## âš™ï¸ åˆ†æè¨­å®š")
        report.append("")
        report.append("| é …ç›® | æ•¸å€¼ |")
        report.append("|------|------|")
        report.append(f"| ATRè¨ˆç®—é€±æœŸ | {self.config.atr_period} |")
        report.append(f"| Variance Ratioèšåˆå°ºåº¦ | {self.config.vr_q} |")
        report.append(f"| åŠè¡°æœŸè¨ˆç®—æœ€å¤§å»¶é² | {self.config.half_life_max_lag} |")
        report.append(f"| å‹•æ…‹æœ€å°è³‡æ–™é‡ | {'å•Ÿç”¨' if self.config.use_dynamic_min_bars else 'åœç”¨'} |")
        report.append("")
        
        # æ™‚é–“æ¡†æ¶åˆ†æçµæœ
        report.append("## ğŸ“ˆ æ™‚é–“æ¡†æ¶åˆ†æçµæœ")
        report.append("")
        
        # å‰µå»ºè¡¨æ ¼æ¨™é¡Œ
        table_headers = ["æ™‚é–“æ¡†æ¶", "Kç·šæ•¸", "C/A", "VR", "åŠè¡°æœŸ", "æ³¢å‹•ç‡", "ååº¦", "å³°åº¦", "è‡ªç›¸é—œ", "å¸‚å ´æ•ˆç‡", "é€šéC/Aæ¸¬è©¦", "ç‹€æ…‹"]
        report.append("| " + " | ".join(table_headers) + " |")
        report.append("|" + "|".join(["---"] * len(table_headers)) + "|")
        
        tested_timeframes = set(report_df['Timeframe'].tolist())
        
        for tf_label, rule in self.config.timeframes.items():
            if tf_label in tested_timeframes:
                row = report_df[report_df['Timeframe'] == tf_label].iloc[0]
                
                # æ ¼å¼åŒ–æ•¸å€¼
                bars = f"{row['Bars']:,}"
                ca = f"{row['C_over_A']:.4f}" if not pd.isna(row['C_over_A']) else "N/A"
                vr = f"{row['VarianceRatio']:.4f}" if not pd.isna(row['VarianceRatio']) else "N/A"
                hl = f"{row['HalfLife_bars']:.1f}" if not pd.isna(row['HalfLife_bars']) else "N/A"
                vol = f"{row['Volatility_Ann']:.4f}" if not pd.isna(row['Volatility_Ann']) else "N/A"
                skew = f"{row['Skewness']:.4f}" if not pd.isna(row['Skewness']) else "N/A"
                kurt = f"{row['Kurtosis']:.4f}" if not pd.isna(row['Kurtosis']) else "N/A"
                autocorr = f"{row['Autocorr_Lag1']:.4f}" if not pd.isna(row['Autocorr_Lag1']) else "N/A"
                me = f"{row['Market_Efficiency']:.4f}" if not pd.isna(row['Market_Efficiency']) else "N/A"
                pass_ca = "âœ…" if row['Pass_CA_0.25'] else "âŒ"
                status = "âœ… å·²æ¸¬è©¦"
                
                report.append(f"| {tf_label} | {bars} | {ca} | {vr} | {hl} | {vol} | {skew} | {kurt} | {autocorr} | {me} | {pass_ca} | {status} |")
            else:
                report.append(f"| {tf_label} | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | N/A | âŒ æœªæ¸¬è©¦ |")
        
        report.append("")
        
        # è©³ç´°åˆ†æ
        report.append("### ğŸ” è©³ç´°åˆ†æ")
        report.append("")
        
        for tf_label, rule in self.config.timeframes.items():
            if tf_label in tested_timeframes:
                row = report_df[report_df['Timeframe'] == tf_label].iloc[0]
                report.append(f"#### ğŸ• {row['Timeframe']} æ™‚é–“æ¡†æ¶")
                report.append("")
                report.append("**åŸºæœ¬çµ±è¨ˆ:**")
                report.append(f"- Kç·šæ•¸é‡: {row['Bars']:,}")
                report.append(f"- å¹³å‡ATR: {row['Avg_ATR_pct']:.4f} ({row['Avg_ATR_pct']*100:.2f}%)")
                report.append(f"- æˆæœ¬/æ³¢å‹•æ¯” (C/A): {row['C_over_A']:.4f}")
                report.append(f"- èµ°å‹¢ä¸€è‡´æ€§ (VR): {row['VarianceRatio']:.4f}")
                report.append(f"- è¨Šè™ŸåŠè¡°æœŸ: {row['HalfLife_bars']:.1f} bars")
                report.append("")
                
                if not pd.isna(row['Volatility_Ann']):
                    report.append("**æŠ€è¡“æŒ‡æ¨™:**")
                    report.append(f"- å¹´åŒ–æ³¢å‹•ç‡: {row['Volatility_Ann']:.4f}")
                    report.append(f"- å ±é…¬ååº¦: {row['Skewness']:.4f}")
                    report.append(f"- å ±é…¬å³°åº¦: {row['Kurtosis']:.4f}")
                    report.append(f"- è‡ªç›¸é—œ(Lag1): {row['Autocorr_Lag1']:.4f}")
                    report.append(f"- å¸‚å ´æ•ˆç‡æ¯”ç‡: {row['Market_Efficiency']:.4f}")
                    report.append("")
                
                if row['Pass_CA_0.25']:
                    report.append("âœ… **é€šéC/A < 0.25æ¸¬è©¦**")
                else:
                    report.append("âŒ **æœªé€šéC/A < 0.25æ¸¬è©¦**")
                report.append("")
        
        # ç¶œåˆå»ºè­°
        report.append("## ğŸ’¡ ç¶œåˆå»ºè­°")
        report.append("")
        
        best_ca = report_df.loc[report_df['C_over_A'].idxmin()] if 'C_over_A' in report_df.columns else None
        best_vr = report_df.loc[report_df['VarianceRatio'].idxmax()] if 'VarianceRatio' in report_df.columns else None
        
        if best_ca is not None and not pd.isna(best_ca['C_over_A']):
            report.append(f"**æœ€ä½³æˆæœ¬æ•ˆç‡æ™‚é–“æ¡†æ¶**: {best_ca['Timeframe']} (C/A: {best_ca['C_over_A']:.4f})")
        
        if best_vr is not None and not pd.isna(best_vr['VarianceRatio']):
            report.append(f"**æœ€é«˜è¶¨å‹¢æ€§æ™‚é–“æ¡†æ¶**: {best_vr['Timeframe']} (VR: {best_vr['VarianceRatio']:.4f})")
        
        report.append("")
        report.append("### ğŸ“‹ æŒ‡æ¨™è§£è®€æŒ‡å—")
        report.append("")
        report.append("- **C/A < 0.25**: æˆæœ¬ç›¸å°æ–¼æ³¢å‹•ç‡è¼ƒä½ï¼Œé©åˆäº¤æ˜“")
        report.append("- **VR > 1**: åè¶¨å‹¢å¸‚å ´ï¼Œé©åˆè¶¨å‹¢ç­–ç•¥")
        report.append("- **VR < 1**: åå‡å€¼å›æ­¸å¸‚å ´ï¼Œé©åˆå‡å€¼å›æ­¸ç­–ç•¥")
        report.append("- **åŠè¡°æœŸ**: å»ºè­°baré€±æœŸç´„ç‚º0.5~1å€åŠè¡°æœŸ")
        report.append("- **æ³¢å‹•ç‡**: åæ˜ å¸‚å ´æ³¢å‹•ç¨‹åº¦")
        report.append("- **ååº¦**: æ­£ååº¦è¡¨ç¤ºå³å°¾è¼ƒé•·ï¼Œè² ååº¦è¡¨ç¤ºå·¦å°¾è¼ƒé•·")
        report.append("- **å³°åº¦**: é«˜å³°åº¦è¡¨ç¤ºæ¥µç«¯å€¼è¼ƒå¤š")
        report.append("- **è‡ªç›¸é—œ**: æ­£å€¼è¡¨ç¤ºè¶¨å‹¢æ€§ï¼Œè² å€¼è¡¨ç¤ºå‡å€¼å›æ­¸")
        report.append("- **å¸‚å ´æ•ˆç‡æ¯”ç‡**: è¶Šæ¥è¿‘1è¡¨ç¤ºå¸‚å ´è¶Šæœ‰æ•ˆç‡")
        
        return "\n".join(report)
    
    def analyze(self) -> pd.DataFrame:
        """åŸ·è¡Œå®Œæ•´åˆ†æ"""
        print("=== Binance æ™‚é–“æ¡†æ¶åˆ†æå™¨ ===")
        print(f"åˆ†æäº¤æ˜“å°: {self.config.symbol}")
        print(f"å¸‚å ´é¡å‹: {self.config.market_type.upper()}")
        
        # åˆ†ææ™‚é–“æ¡†æ¶
        report_df = self.analyze_timeframes()
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_reports(report_df)
        
        return report_df


# ä¾¿æ·å‡½æ•¸
def analyze_symbol(symbol: str, market_type: str = "spot", data_days: int = 365) -> pd.DataFrame:
    """åˆ†ææŒ‡å®šäº¤æ˜“å°çš„ä¾¿æ·å‡½æ•¸"""
    config = BinanceAnalyzerConfig(
        symbol=symbol,
        market_type=market_type,
        data_days=data_days
    )
    analyzer = BinanceTimeframeAnalyzer(config)
    return analyzer.analyze()


def get_available_symbols(market_type: str = "spot") -> List[str]:
    """ç²å–å¯ç”¨çš„äº¤æ˜“å°åˆ—è¡¨"""
    return BinanceAPI.get_available_symbols(market_type)


def get_popular_symbols(market_type: str = "spot", limit: int = 50) -> List[str]:
    """ç²å–ç†±é–€äº¤æ˜“å°åˆ—è¡¨"""
    return BinanceAPI.get_popular_symbols(market_type, limit)


if __name__ == "__main__":
    # é è¨­é…ç½® - å¯ä»¥ä¿®æ”¹é€™è£¡ä¾†åˆ†æä¸åŒçš„äº¤æ˜“å°
    config = BinanceAnalyzerConfig(
        symbol="ETHUSDT",
        market_type="spot",  # æˆ– "futures"
        data_days=365
    )
    
    analyzer = BinanceTimeframeAnalyzer(config)
    analyzer.analyze()
